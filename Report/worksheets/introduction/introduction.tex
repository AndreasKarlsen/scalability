\makeatletter \@ifundefined{rootpath}{\input{../../setup/preamble.tex}}\makeatother
\worksheetstart{Introduction}{1}{September 5, 2014}{Kasper}{../../}
\section{Motivation}
% Moores law, skalér med flere kerner, ikke højere CPU
% Krav til at applikationer kræver mere ydelse
% Focus på skalering til flere computere i.e. parallel computing, ikke kun flere kerner
% Brug for en evolution, inden for tilgange til at skrive parallele programmer
% Vi vil kigge på concurrency inden for rammerne af samme maskine
Moore's law\cite{moore1965cramming} is the empirical observation that the number of transistors per area, on a integrated circuit, was approximately doubled roughly every 18 months\cite[p. 203]{mack2011fifty}. As a result, processing speed kept increasing as more transistors where added. This increase has however stagnated and processing power has mainly increased in the form of additional processing cores, as opposed to the speed of each of these processing cores\cite[p. 22]{sevenModels}. That is, computers have moved from having a \ac{CPU} consisting of one single core to one having multiple cores. This tendency is displayed in \bsref{fig:moores_in_reality}. 
\label{chap:introduction}

\begin{figure}[htbp]
\centering
 \includegraphics[width=0.9\textwidth]{\rootpath/worksheets/introduction/figures/moores_core_vs_frequency} 
 \caption{A comparison of the development of Transistors, Frequency, and Cores\cite{isca2009}. A change of the tendency occurred around 2005. The overall number of transistors has kept increasing, but the increase in MHz, has been substituted by an increase in the number of cores.}
\label{fig:moores_in_reality}
\end{figure}

While the need for applications to scale over multiple cores has arisen, so has the need to scale applications over multiple servers\lone{udokumenteret påstand?}. With the rise of the Internet, the number of very large services supporting millions of users has increased. Due to this, the need for\lone{udokumenteret påstand} scalable systems, and programming languages which support the scalable approach has arisen. Previously, when scalability issues arose a company might invest in a new machine capable of handling the load, effectively discarding the investment of purchasing the old machine\cite[p. 2]{haller2007actors}. A more modern approach entails scaling the service over a set of low end machines, adding and removing machines as needed. However, the applications\lone{er det applications el. developers?} need to be aware of this approach when developed. A concurrency model\lone{hvad skal den bruges til?} that can be used on both a single machine as well as in a distributed fashion, could potentially assist in addressing both scaling over multiple cores and multiple servers.

Programming languages developed while it was believed that single core performance would keep increasing, such as assembly and C, were closely related to the Von Neumann architecture. As a consequence, the programming model was designed for synchronous execution. This introduces a challenge in how programs should be written to execute efficiently on a multi-core processor. A lot of effort has been invested into identifying suitable ways of programming against such architectures\cite{shavit1997software}\cite{haller2007actors}\cite{hewitt2014actor}\cite{scherer2005advanced}. \lone[inline]{Nævn et par eksempler}
\andreas[inline]{Purpose!}

% Formål med preliminary analysis
This chapter contains an analysis of prior work related to concurrency. It will be conducted by investigating papers, articles, and other research material of relevance, in order to discover state of the art, and open problems within the area of concurrency models. The purpose of the analysis is to establish an overview which will be used to choose the further path of our investigation.
\label{chap:preliminary_analysis}
% Moores law, skalér med flere kerner, ikke højere CPU
% Krav til at applikationer kræver mere ydelse
% Focus på skalering til flere computere i.e. parallel computing, ikke kun flere kerner
% Brug for en evolution, inden for tilgange til at skrive parallele programmer
% Vi vil kigge på concurrency inden for rammerne af samme maskine

%Threads and locks duer ikke
%Hvad er der behov for
%Hvad andet findes der, der opfylder behovet
\section{Related work}
\lone[inline]{Hvad er current state of the art, related work, open problem?}

In ``The Free Lunch is Over''\cite{sutter2005free}, it is claimed that the era of gaining performance increase without changing a program is over:

\bsqoute{[...] if you want your application to benefit from the continued exponential throughput advances in new processors, it will need to be a well-written concurrent (usually multithreaded) application. And that’s easier said than done, because not all problems are inherently parallelizable and because concurrent programming is hard.}{Herb Sutter}

In other words, hardware limitations in the processor development are having an impact on the way software should be developed to utilize the full potential of multi-core processors. The key to take advantage of the raw performance of future multicore processors, is to enable the programmer to harvest that performance\cite[p. 31]{asanovic2006landscape}. In ``The landscape of Parallel Computing Research''\cite{asanovic2006landscape} they propose that a programming model needs to enable productivity and implementation efficiency\cite[p. 31]{asanovic2006landscape}. Productivity is defined as the speed a programmer can develop a program, and implementation efficiency is defined as the runtime speed.

Optimally\lone{says who? why? ikke altid?}, productivity and implementation efficiency of a concurrency model should both be as high as possible. While the wish to enable both productivity and implementation efficiency seems reasonable, the two goals are often conflicting. An abstraction over concurrency mechanisms frees the programmer from low level details, and increases productivity. However, by using the abstraction, the programmer loses the ability to fine tune the underlying concurrency implementation for performance. A concurrency model must therefore seek to find the right abstraction, that gives the programmer enough abstraction for a productivity increase, without losing too much implementation efficiency.

With these discoveries taken into account, a focus on concurrency models with the characteristic of abstraction over low level details, and a solid performance is of special interest for our investigation.

\section{Models to Investigate}
\andreas[inline]{Redegør for relevansen for valg af de enkelte modeller. Skriv en linie eller to i starten af hvert afsnit, om hvorfor modellen er valgt}
\lone[inline]{Forsøg at præsentere de forskellige modeller isoleret}

The purpose of this presentation\lone{subsection?} is to document our preliminary concurrency model analysis, in order to justify the choice of models to analyse further. For each model, a reason for looking into it will be given followed by a short description, which will provide an overview of the model. Later the chosen models will be presented further in depth.\andreas[inline]{Lav en reference til den uddybende forklaring for de enkelte modeller når den er færdig}

\subsection{\acl{TL}}
The \ac{TL} model has been chosen based on its historical significance and widespread commercial use\cite[p. 58]{sutter2005software}. The traditional \ac{TL} approach is based on shared memory and uses locks to limit the access to critical regions in order to ensure correct execution\cite[p. 1]{saha2006mcrt}. The use of threads and locks leads to a number of issues, including: deadlocks, difficult fined-grained synchronization and no support for error recovery\cite[p. 187]{saha2006mcrt}. The \ac{TL} model has been implemented in many languages, including C and Java. 

A problem of particular importance in modern software development is composition of code segments. Many programs rely on libraries to handle part of its operations. Using the \ac{TL} approach it is however not guarantied that combining two lock based code segments will result in a correct program\cite[p. 56]{sutter2005software}.

Using the \ac{TL} approach it is left up to the programmer to identity correct lock placements as well as balancing lock granularity vs performance\cite[p. 49]{harris2005composable}. \ac{TL} concurrency is generally believed to be hard to get right\cite[p. 92]{herlihy2003software}. Arguments have been made for the case that the \ac{TL} approach is insufficient for today's concurrency needs and that new models which put less strain on the programmer are needed\cite[p. 3]{jones2007beautiful}\cite[p. 48]{harris2005composable}.

\subsection{Actor model}
%Formalism-centric programming models, such as Actors [Hewitt et al 1973], try to reduce the chance of programmer making mistakes by having clean semantics and offer the chance to remove bugs by verifying correctness of portions of the code. "A view from berkeley, p. 33"
The actor model is inspired by physical laws and can be used to model, understand and reason about a wide range of concurrent systems\cite{hewitt2014actor}. The model targets both shared- and distributed-memory architectures and has support for fault tolerance\cite[Chap. 5]{sevenModels}. It is a general model for concurrency that can be used with almost any language but it is often associated with Erlang\footnote{\url{http://erlang.org}}.
 
The idea of the actor model is to use actors as the fundamental unit of computation. An actor has the following essential elements of computation\cite{actorLangNextVideo}: Processing, storage, and communication.

The actor encapsulates state and communicates with other actors by sending messages. In response to a message an actor can\cite{hewitt2014actor}:
\begin{itemize}
\item Create new actors
\item Send messages to actors it knows
\item Modify internal behavior (how the next message it receives should be handled)
\end{itemize}
Actors interact with one another through asynchronous message passing. For an actor to be able to send a message to another actor it must have the address of the actor. An actor \bscode{A} can know the address of another actor \bscode{B} if \bscode{A} creates \bscode{B} or receives the address of \bscode{B} as a message from another actor.

An actor has a mailbox which messages sent to the actor arrives in. The actor dequeues the mailbox and processes one message at a time\footnote{Not true for recursion}. Messages sent can take arbitrarily long time to arrive, and if sent concurrently can arrive in a mailbox in any order\cite{hewitt2014actor}.

The actor model avoids the deadlocks and race conditions present in the \ac{TL} model, by avoiding shared state\citep[Chap. 32]{odersky2011programming}. Instead the actor model allows isolated mutable state on actors and rely solely on asynchronous message passing between actors.

\subsection{\acl{Rx}}
At Microsoft Research, Erik Meijer\andreas{Known from....} and his team have developed \ac{Rx} which is a library for composing asynchronous and event-based programs. The approach has gained a lot of traction in the developer community, and the idea is spreading to various platforms, for instance Netflix have ported it to Java\footnote{\url{https://github.com/ReactiveX/RxJava/}}, and Facebook ported it to JavaScript\footnote{\url{http://facebook.github.io/react/}}. Google is also inspired by the idea in their new language Dart\footnote{\url{https://www.dartlang.org/docs/tutorials/streams/\#error-handling}}

\ac{Rx} gives reactive capabilities to mainstream imperative languages, such as Java and C\#\footnote{\url{https://Rx.codeplex.com/}}. The idea is, to abstract over the complexity that asynchronous computations introduces, by providing a way to orchestrate asynchronous data streams in a uniform way, regardless of the underlying concurrency model.

It is based on the idea of the Observer Pattern\cite{gamma1994design}. That is, whenever the subject of observation, called an observable, is changed, the observers is notified, and can react to the change. This is said to be a push based approach, since changes is pushed out the its observers. This is both true for the Observer Pattern and \ac{Rx}. Since \ac{Rx} is intended for asynchronous tasks that can fail, for example network calls, it extends the Observer Pattern and provides a way to notify its observers whenever an error occurred or if the stream ends.

\ac{Rx} provides a way to deal with asynchronous data streams, the same way programmers deal with synchronous data streams. In Java, a synchronous data stream is a data structure which implements the \bscode{Iterable} interface\footnote{\url{http://docs.oracle.com/javase/7/docs/api/java/lang/Iterable.html}}. However, while iterations over an \bscode{Iterable} blocks between each iteration, \ac{Rx} does not block between each push of the next element. This a key difference, since not blocking while doing concurrency computations is essential for performance.

\ac{Rx} can hardly be called a concurrency model itself. However, it provides a uniform way, to structure asynchronous tasks independently of the underlying concurrency model. The underlying model could be \ac{TL}, actors, or a third alternative. It does not matter, since this is abstracted away from the client, that treat all interaction with Observables as asynchronous.

\subsection{\acl{STM}}
\ac{STM} has been viewed by many people as a promising direction for solving concurrency issues\cite{sutter2005software}. There has been a lot of attention to this area, and there is still active research. Due to this, it is a natural candidate of interest.

\ac{STM} takes an approach to concurrency, that is based on transactions as known from database theory\cite[p. 1]{shavit1997software}. \ac{STM} transitions are atomic and isolated. Atomic meaning that either all writes in a given transaction are committed, or non of them are, while isolated means that from a given transaction \bscode{T}, any other concurrently running transaction will have no impact on the values committed by \bscode{T} when \bscode{T} succeeds\cite[p. 102]{sevenModels}. These properties are similar to the \ac{ACID} properties known from databases\cite[p. 754]{elmasri2011fundamentals}.

\ac{STM} is implemented in a number of languages, including Clojure\cite[p. 101]{sevenModels}, Concurrent Haskell\cite{harris2005composable} and Scala\cite{goodman2011muts} either directly or using a library. Generally the idea is that programmers specify regions which are to be executed as a transaction. The compiler or library then takes care of ensuring that the \ac{STM} transaction principles are maintained and that the transactions are eventually committed\cite[p. 1]{saha2006mcrt}. The transaction might be\lone{Hvordan afgøres det?} retried one or more times in the process, if any other transactions read or modified the used data.

The strength of \ac{STM} lies in the avoidance of many of the issues\lone{Nævner I dem?} that plague the traditional \ac{TL} approach. \ac{STM} can avoid deadlocks, priority inversion and eliminates the issue of balancing lock granularity vs performance\cite[p. 1]{harris2005composable}.

\subsection{Communicating Sequential Processes}
The \ac{CSP} model was invented by C. A. R. Hoare and it is widely regarded as one of the most influential papers in computer science\cite{abdallah2005communicating}. 

\ac{CSP} has influenced the design of numerous languages and it is implemented either directly in the language or indirectly in the form of a library. This includes programming languages such as Ada, occam and Concurrent ML\cite{abdallah2005communicating}. The model has still a lot of attention and the recent popularity is especially due to the Go\footnote{https://golang.org/doc/faq\#csp} programming language developed by Google, as Go builds their concurrency model on the ideas of \ac{CSP}\cite[Chap. 6]{sevenModels}. \ac{CSP} is therefore deemed as an important and viable candidate for consideration.

A process in \ac{CSP} is a basic construct that operate independently and communication between such processes enables concurrency\cite{ibmCSP}. There is no shared state between processes and communication is accomplished solely through message passing to and from channels. A channel in \ac{CSP} is a first-class queue where messages are added to in one end and removed from in the other\cite[Chap. 6]{sevenModels}. It is possible to have arbitrarily many reader/writer processes on a channel. 

The strength of \ac{CSP} lies in avoiding many of the issues that is related to shared state\toby{Hvilke helt præcist? race hazards, deadlocks, livelocks, and resource starvation?} by modeling computations as independent isolated processes which communicate together through channels. 

% nævn den originalt er en mathematical model?
%Noget om at CSP har ændret sig over tid? Actor har altid været den samme
%Til valg af modeller: CSP og Actor minder meget om hinaden, derfor vælger vi kun at se på Actor (men der er forskelle! evt. vælg at pointere dem ud, eller skriv et lille afsnit om det i Actor afsnittet)
	%Evt. begrund med at vi vælger CSP fra fordi det er mere matematisk orienteret, hvilket ikke er attraktivt for 
	%CSP har fokus på channels (kommunikation mellem entities), hvor Actor har fokus på Actors (entities)

\section{Problem Statement}
The motivation of this project is to contribute with a clarification of the productivity and implementation efficiency of the chosen concurrency models\lone{Passer det med titlen?}. We wish to investigate different concurrency models, in order to discover the strengths and weaknesses of these models and identify problem areas in which they are applied best. The focus will be on concurrency models that have seen widespread use, as well as models that currently are receiving academic and industrial interest.

In our preliminary analysis, we briefly covered the traditional threads and locks model, as well the actor based, event-driven, and software transactional memory approaches. Threads and locks have been selected based on its widespread use and historical significance, while the remaining models have been chosen based on their up and coming usage or ongoing research efforts. Each of these models also have a vastly different approach to handling concurrency, and will provide varying perspectives.

In order to structure our investigation into concurrency models, we have extracted a number of problems statement questions. The questions and selected models are based on findings presented in our preliminary analysis, which is described in \bsref{chap:introduction} and \bsref{chap:preliminary_analysis}. These questions will serve as a guideline for our further investigation, and will be used to conclude upon the project in \bsref{chap:conclusion}.

The questions we seek to answer are:
\begin{enumerate}
\item Which problems exist with concurrency in a multithreaded\lone{hvor kom det fra?} environment? 
\item What are the characteristics of the selected models? Including their strengths and weaknesses.
\item How do the selected models handle known\lone{alle?} concurrency issues?
\item In what problem domains are the models most applicable?\lone{og hvad så når I har det?}
\item Comparing models against \ac{TL}
\item Performance test
\end{enumerate}

\subsection{Learning Goals}
Along with the definition of a problem statement, a set of learning goals have been defined. While answering the questions presented in the problem statement is the mains focus, the learning goals can be viewed as a set of sub goals that are aimed at stimulating our learning.

The learning goals are defined as:
\begin{enumerate}
\item Learn what concurrency models exists and in what setting they are best applied
\item Produce a sample implementation using each of the selected models in order to further our understanding\lone{hands on experience}
\item Get familiar with the the Scala\footnote{\url{http://www.scala-lang.org/}} programming language
\end{enumerate}

\worksheetend
