\makeatletter \@ifundefined{rootpath}{\input{../../setup/preamble.tex}}\makeatother
\worksheetstart{Method}{1}{April 24, 2013}{Andreas}{../../}
\section{Research approach}
We want to investigate the known problems of concurrency. Then we want to follow the pattern of investigating the approach and implement a test of the approaches

\section{Definition of test approach}
In order to investigate the performance of the selected models, a performance test will be conducted. The $k$-means clustering algorithm has been selected as the basis for the comparison. $k$-means aims at clustering $n$ data points, into $k \leq n$ clusters\cite[p. 451]{dataminingconceptsandtechniques}\cite[p. 128]{epstein2011towards}. Each cluster $k$ is initially assigned a random centroid representing the mean of the cluster. For each of the data points, a distance to the centroid of each of the $k$ clusters is calculated. The data point is then assigned to the cluster to which it is closest. After every data points has been assigned, new centroids are calculated, based on the data points assigned to the clusters. The process is then repeated, using the newly calculated clusters centroids as the basis for the distance calculations. The algorithm terminates when the cluster centroids stop changing or or when a set number of iterations has been completed\cite[p. 128]{epstein2011towards}.

$k$-means is a good basis for performance analysis of concurrency models as it is computationally demanding and easily partitioned into concurrent tasks\cite[p. 128]{epstein2011towards}. The performance test will be based on a data set of one million vectors consisting of one hundred integer data points. Five clusters will be created using a maximum of eight concurrent tasks. The algorithm will run for ten iterations. In the context of performance analysis, only the effort taken to cluster the data is of interest, as opposed to the resulting clustering. As a result, randomly generated data is sufficient.

\kasper[inline]{distance metric}
\kasper{Ved ikke om vi skal forklare map reduce?}
The implementations will follow a template similar to that of Map-Reduce\cite{dean2008mapreduce}, know from functional programming as well as the Google and Hadoop MapReduce frameworks. MapReduce employs a set of mappers to apply a function to each data point. This function outputs a number of results that are then aggregated to the final result using a reducer. This is analogous to the \bscode{map} and \bscode{reduce} functions, know from functional programming. For the $k$-means performance test, a set of mappers will be assigned a set of vectors, for which it will calculate the distance to each of the $k$ cluster centroids and assign it to the nearest cluster. A reducer will then aggregate the results from the mappers and calculate the new cluster centroids. The process will continue until the stated 10 iterations are achieved.

In order to produce comparable results across multiple implementations, the languages employed will be limited to languages running on the \ac{JVM}.

\section{Documentation}
We will document alongside our investigation

\worksheetend